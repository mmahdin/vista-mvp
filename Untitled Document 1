i have a clustering service in python.
i want to impleemt the clustering class and functions:
new_groups = self.clusterer.cluster_users(available_users)
which the available_users is a list of data like:
UserLocation(user_id=1, origin_lat=35.9725713, origin_lng=50.7328994, destination_lat=35.9591762, destination_lng=50.6883034, stored_at=datetime.datetime(2025, 8, 1, 22, 6, 31, 467604))
which UserLocation is:
@dataclass
class UserLocation:
    user_id: int
    origin_lat: float
    origin_lng: float
    destination_lat: float
    destination_lng: float
    stored_at: datetime
    @property
    def origin_coords(self) -> Tuple[float, float]:
        return (self.origin_lat, self.origin_lng)
    @property
    def destination_coords(self) -> Tuple[float, float]:
        return (self.destination_lat, self.destination_lng)
    def to_dict(self) -> Dict:
        return {
            'user_id': self.user_id,
            'origin_lat': self.origin_lat,
            'origin_lng': self.origin_lng,
            'destination_lat': self.destination_lat,
            'destination_lng': self.destination_lng,
            'stored_at': self.stored_at.isoformat()
        }

The output should be something like this:
groups = []
@dataclass
class ClusterGroup:
    group_id: str
    users: List[UserLocation]
    created_at: datetime
    meeting_point_origin: Optional[Tuple[float, float]] = None
    meeting_point_destination: Optional[Tuple[float, float]] = None
    status: str = "forming"  # forming, complete, expired
    def is_complete(self) -> bool:
        return len(self.users) == 3
    def has_user(self, user_id: int) -> bool:
        return any(u.user_id == user_id for u in self.users)
    def get_user_ids(self) -> List[int]:
        return [u.user_id for u in self.users]
    def to_dict(self) -> Dict:
        return {
            'group_id': self.group_id,
            'users': [user.to_dict() for user in self.users],
            'created_at': self.created_at.isoformat(),
            'meeting_point_origin': self.meeting_point_origin,
            'meeting_point_destination': self.meeting_point_destination,
            'status': self.status,
            'user_count': len(self.users)
        }
group = ClusterGroup(
group_id=f"group_{user1.user_id}_{best_pair.user_id}_{third_user.user_id}_{int(time.time())}",
users=group_users,
created_at=datetime.now(timezone.utc),
meeting_point_origin=origin_meeting,
meeting_point_destination=dest_meeting,
status="complete"
)
groups.append(group)

i want to group all users into groups of 3 users whose origin and destination are close enough. so my output should be multiple groups with 3 users.
i look for a fast algorithm that can handle newly added data. My naive approach is:
Consider a graph (this is our whole space of the universe; we extend it later):
place = "Savojbolagh County, Alborz Province, Iran"
G = ox.graph_from_place(place, network_type='walk')
I split the map apart into several pockets. Then I only cluster the users whose origin and destination are in the same pockets. in this way, i can use the walking distance of the origin and destination for each user in the same buckets..

خب حالا روی ساختن باکت و اختصاص افراد به این باکت ها فکر کنیم. برای ساختن باکت، باید یه گراف مپ (G) رو بگیریم و اون رو به باکت‌هایی تبدیل کنیم. بعدش که مپ به باکت تبدیل شد، باید یوزر هارو به باکت ها اختصاص بدیم. اینکار کمی باید با دقت انجام بشه. چون ممکنه نیاز باشه یک یوزر رو به دوتا باکت اختصاص بدیم. مثلا فرض کن یک یوزر نزدیک مرز دوتا باکت قرار داشته باشه. در این صورت این یوزر باید توی هردوتا باکت قرار بگیره. اما یوزر هایی که خیلی از مرز باکت فاصله دارن فقط توی یک باکت قرار میگیرن. پس ممکنه بعضی از یوزرها توی چندتا باکت باشن که باید حواستمون باشه که توی دوتا گروه بعدا قرار نگیرن (هر یوزر فقط میتونه توی یه گروه دسته بندی بشه).
بعدش باید یوزهایی که مبدا و مقصدشون باکت‌های مشترکی دارن رو دسته بندی کنن. (یعنی یجور باکت دیگه هست که میگه کدوم یوز‌ها توی مبدا و مقصد مشترک هستن. یعنی باید به اندازه باکت ها به توان دو باکت داریم که یوزها رو تقسیم بندی میکنه.)
حالا که ما میدونیم هر یوزر مبدا و مقصدش توی کدوم باکت هست میریم سراغ دسته بندی دقیق یوزرها که اونارو گروه بندی کنیم. 

بعدش که عملیات خوشه بندی روی تمام باکت ها انجام شد، یوز‌ها یا توی یه گروه قرار گرفتن، یا هیچ گروهی ندارن. حالا باید یوز‌هایی که گروه سه تایی دارن رو کنار بذاریم و  سعی کنیم یوزرهایی که هیچ گروه ندارن رو به گروه‌های دوتایی اضافه کنیم (در صورت امکان)



So let's focus on creating buckets. Please write the code that gets the G and makes buckets. and then assigning two buckets to a user (origin and destination bucket).
After that, do the precise clustering for each pair of buckets that are not empty to find the users whose origin and destination are close enough (walking distance).
till now, we find some companions (up to 2) for each user, who have common buckets.
But with this approach, we are not good for the users who are on the border of the buckets. i mean, maybe a user who is on the border of two buckets can find companions on the bucket that are not blong to him, but are close with him. 
So to solve this issue, we add a second try for the users who don't find any companions (or find one companion and look for the second one to complete the group). in this try, we look for the nearest user in the 9 buckets, where the main bucket is in the center (looks like a square 3 by 3). in other words, we extend the bucket for each user to find the companion (to apply the persice algorithms that are based on walking distance on a larger bucket).

an example for clarification: in two buckets only have 2 users (origin and destination buckets only have 2 uses) and these users are close to each other in the origin and destination by walking distance. so i should groupt them and then searching for other user to complete the groupt.



============================================================================================================

i want to impleemt a clustering service.

i want to group all users into groups of 3 users whose origin and destination are close enough. so my output should be multiple groups with 3 users.
i look for a fast algorithm that can handle newly added data. My naive approach is:

first:
{

I have a graph from OpenStreetMap, for example, the following graph:
place = "Savojbolagh County, Alborz Province, Iran"
G = ox.graph_from_place(place, network_type='walk')
and i have a function that takes this graph and splits it into multiple buckets. Each location should fall into only one bucket. Each bucket should have several attributes, including the center of the bucket and the number of nodes in the bucket.
the output is someting like this:
@dataclass
class Bucket:
    """Class to represent a bucket with its attributes"""
    id: int
    center_lat: float
    center_lon: float
    node_count: int
    nodes: List[int]
    bbox: Tuple[float, float, float, float]  # (min_lat, min_lon, max_lat, max_lon)

[ Bucket(id=10, center_lat=np.float64(35.99076753333333), center_lon=np.float64(50.841244100000004), node_count=3, nodes=[6044580744, 6044580746, 12666284362], bbox=(np.float64(35.9892753), np.float64(50.8409144), np.float64(35.9918392), np.float64(50.8417962))),
 Bucket(id=995, center_lat=np.float64(35.99037147142857), center_lon=np.float64(50.71779345714286), node_count=7, nodes=[5039841510, 5039841638, 7368104569, 7368104577, 7368104583, 7368104584, 7368159011], bbox=(np.float64(35.9894731), np.float64(50.7168462), np.float64(35.9916733), np.float64(50.7194007))),
...]
which noeds are for node in G.nodes().
}

second:{
After the map is converted to buckets, we need to assign users to those buckets — meaning, for each user, we should quickly assign two buckets: one for the origin and one for the destination. The goal is to quickly identify which users share both origin and destination buckets. So please write a function that takes all the users (i.e., origin and destination lat/lon along with user_id) and determines which users have buckets in common (for both origin and destination).
}

============================================================================================================

i want to impleemt a clustering service.

i want to group all users into groups of 3 users whose origin and destination are close enough. so my output should be multiple groups with 3 users.
i look for a fast algorithm that can handle newly added data. My naive approach is:

first:
I want to get a graph from OpenStreetMap, for example, the following graph:
place = "Savojbolagh County, Alborz Province, Iran"
G = ox.graph_from_place(place, network_type='walk')
Then I want a function that takes this graph and splits it into multiple buckets. Each location should fall into only one bucket. Each bucket should have several attributes, including the center of the bucket and the number of nodes in the bucket. Please write this function in Python.


second:
After the map is converted to buckets, we need to assign users to those buckets — meaning, for each user, we should quickly assign two buckets: one for the origin and one for the destination. The goal is to quickly identify which users share both origin and destination buckets. So please write a function that takes all the users (i.e., origin and destination lat/lon along with user_id) and determines which users have buckets in common (for both origin and destination).


i look for fast algorithm like hasing. i mean, w


 بعدش که مپ به باکت تبدیل شد، باید یوزر هارو به باکت ها اختصاص بدیم یعنی هر یوزر رو خیلی سریع بتونیم دوتا باکت بهش اختصاص بدیم یکی برای مبدا و یکی برای مقصد. هدف اینه که خیلی سریع بتونیم مشخص کنیم کدوم یوزر ها توی مبدا و مقصد مشترک هستند (باکت هاشون مشترک هست). پس لطفا یک تابع بنویس که تمام یوزر هارو بگیره (یعنی lat و lon مبدا و مقصد به همراه user_id) و بعدش مشخص کنه که کدوم یوزرها باهم مشترک هستند (توی باکت مبدا و مقصد).


. اینکار کمی باید با دقت انجام بشه. چون ممکنه نیاز باشه یک یوزر رو به دوتا باکت اختصاص بدیم. مثلا فرض کن یک یوزر نزدیک مرز دوتا باکت قرار داشته باشه. در این صورت این یوزر باید توی هردوتا باکت قرار بگیره. اما یوزر هایی که خیلی از مرز باکت فاصله دارن فقط توی یک باکت قرار میگیرن. پس ممکنه بعضی از یوزرها توی چندتا باکت باشن که باید حواستمون باشه که توی دوتا گروه بعدا قرار نگیرن (هر یوزر فقط میتونه توی یه گروه دسته بندی بشه). اینکه یوزر بتونه چندتا باشه دلیش اینه که اگر برای یه یوز توی یه نود، هیچ یوزر مشابهی پیدا نشد، توی باکت دیگه براش دنبال گروه بگردیم. در ادامه بیشتر توضیح میدم.
}


من به یک الگوریتم سریع نیاز داریم که مثل هش فانکشن عمل کنه. یعنی وقتی لوکیشن مبدا و مقصد یوزر رو میگیره، بگه که یوزتوی یه باکتی قرار میگره. یعنی یه تابع باشه که وقتی یه لوکیشن میگیره، سریع بگه که این لوکیشن برای کدوم باکت هست. بعدش که تمام یوزرها توی باکت ها قرار گرفتن، باید یوزرهای مشابه رو پیدا کنیم که مبد





========================================================================================================================================================================================================================





لطفا فقط متن زیر رو به انگلیسی ترجمه کن:

{
من یک کلاس دارم که یک لیست باکت دریافت میکنه و همچنین یک لیست از یوزر هارو و درنهایت مشخص میکنه که هر یوزر توی چه باکتی هست. لیست باکت‌ها شبیه اینه:
[Bucket(id=2, center_lat=np.float64(36.0292331375), center_lon=np.float64(50.8322946), node_count=8, nodes=[9524600425, 9524600433, 9524600445, 9524600459, 12009646132, 12009646138, 12009646139, 12009646140], bbox=(np.float64(36.0281474), np.float64(50.8314094), np.float64(36.0308628), np.float64(50.8345416))), ...]

و یوزرها هم شبیه این هستن:
[UserLocation(user_id=1, origin_lat=35.9725713, origin_lng=50.7328994, destination_lat=35.9591762, destination_lng=50.6883034, stored_at=datetime.datetime(2025, 8, 1, 22, 6, 31, 467604)), ....]

حالا من میخوایم یه کلاس بنویسم که با دریافت یوزرهای دسته بندی شده (od_assignments):
self.bucket_assigner = FastBucketAssigner(self.kmeans_buckets)
od_assignments = self.bucket_assigner.assign_users_to_od_buckets(available_users)
برای هر گروه در od_assignments یک دسته بندی دقیق انجام بده و گروه های نهایی رو مشخص کنه. برای اینکار باید برای هر گروه توی od_assignments، بیاد فاصله پیاده روی بین مبدا و مقصد هر دو یوزر رو محاسبه کنه و سعی کنه یوزرهای هر گروه از od_assignments رو به چندین گروه سه نفره تقسیم کنه که کمترین فاصله رو به هم دارن.
در نهایت باید خروجی به شکل زیر باشه:



}




I have a class that takes a list of buckets and a list of users and ultimately determines which bucket each user belongs to. The list of buckets looks like this:
[Bucket(id=2, center_lat=np.float64(36.0292331375), center_lon=np.float64(50.8322946), node_count=8, nodes=[9524600425, 9524600433, 9524600445, 9524600459, 12009646132, 12009646138, 12009646139, 12009646140], bbox=(np.float64(36.0281474), np.float64(50.8314094), np.float64(36.0308628), np.float64(50.8345416))), ...]
And the users look like this:
[UserLocation(user_id=1, origin_lat=35.9725713, origin_lng=50.7328994, destination_lat=35.9591762, destination_lng=50.6883034, stored_at=datetime.datetime(2025, 8, 1, 22, 6, 31, 467604)), ....]
Now, I want to write a class that, given the categorized users (od_assignments):
self.bucket_assigner = FastBucketAssigner(self.kmeans_buckets)
od_assignments = self.bucket_assigner.assign_users_to_od_buckets(available_users)
performs a precise grouping for each group in od_assignments and determines the final groups. To do this, for each group in od_assignments, it should calculate the walking distance between the origin and destination of each pair of users and try to divide the users in each group from od_assignments into multiple three-person groups with the shortest distances to each other.
The final output should be in the following format:
groups = []
@dataclass
class ClusterGroup:
    group_id: str
    users: List[UserLocation]
    created_at: datetime
    meeting_point_origin: Optional[Tuple[float, float]] = None
    meeting_point_destination: Optional[Tuple[float, float]] = None
    status: str = "forming"  # forming, complete, expired
    def is_complete(self) -> bool:
        return len(self.users) == 3
    def has_user(self, user_id: int) -> bool:
        return any(u.user_id == user_id for u in self.users)
    def get_user_ids(self) -> List[int]:
        return [u.user_id for u in self.users]
    def to_dict(self) -> Dict:
        return {
            'group_id': self.group_id,
            'users': [user.to_dict() for user in self.users],
            'created_at': self.created_at.isoformat(),
            'meeting_point_origin': self.meeting_point_origin,
            'meeting_point_destination': self.meeting_point_destination,
            'status': self.status,
            'user_count': len(self.users)
        }
group = ClusterGroup(
group_id=f"group_{user1.user_id}_{best_pair.user_id}_{third_user.user_id}_{int(time.time())}",
users=group_users,
created_at=datetime.now(timezone.utc),
meeting_point_origin=origin_meeting,
meeting_point_destination=dest_meeting,
status="complete"
)
groups.append(group)
and this is my FastBucketAssigner class:
class FastBucketAssigner:
    def __init__(self, buckets: List[Bucket]):
        self.buckets = buckets
        self.num_buckets = len(buckets)
        
        # Create spatial index for fast lookup
        self.bucket_ids = np.array([b.id for b in buckets])
        self.min_lats = np.array([b.bbox[0] for b in buckets])
        self.min_lons = np.array([b.bbox[1] for b in buckets])
        self.max_lats = np.array([b.bbox[2] for b in buckets])
        self.max_lons = np.array([b.bbox[3] for b in buckets])
        
        # Create a mapping from bucket_id to index for quick lookup
        self.bucket_id_to_index = {bucket.id: i for i, bucket in enumerate(buckets)}

    def get_nearest_node(self, lat, lon):
        """
        Given latitude and longitude, return the (lat, lon) of the nearest node in the graph G.
        """
        # Find the nearest node ID
        nearest_node = ox.distance.nearest_nodes(G, X=lon, Y=lat)
        
        # Extract node coordinates
        node_lat = G.nodes[nearest_node]['y']
        node_lon = G.nodes[nearest_node]['x']
        
        return node_lat, node_lon
        
    def find_bucket_for_point(self, lat: float, lon: float) -> int:
        """Find which bucket a point (lat, lon) belongs to. Returns bucket_id or -1 if not found."""
        lat, lon = self.get_nearest_node(lat, lon)

        inside_mask = (
            (self.min_lats <= lat) & (lat <= self.max_lats) &
            (self.min_lons <= lon) & (lon <= self.max_lons)
        )
        
        indices = np.where(inside_mask)[0]
        if len(indices) > 0:
            return self.bucket_ids[indices[0]]
        return -1
    
    def assign_users_to_od_buckets(self, users: List[UserLocation]) -> Dict[Tuple[int, int], List[UserLocation]]:
        """Assign users to origin-destination bucket pairs."""
        od_buckets = defaultdict(list)
        
        for user in users:
            origin_bucket = self.find_bucket_for_point(user.origin_lat, user.origin_lng)
            dest_bucket = self.find_bucket_for_point(user.destination_lat, user.destination_lng)
            
            if origin_bucket != -1 and dest_bucket != -1:
                od_buckets[(origin_bucket, dest_bucket)].append(user)
        
        return dict(od_buckets)


========================================================================================================================================================================================================================

In this project, my goal is to create a feature matrix for a set of users, each with an origin and a destination location. The spatial scope of this project is limited to a graph extracted from OpenStreetMap, and it is assumed that all possible locations are defined solely within this graph.

place = "Savojbolagh County, Alborz Province, Iran"
G = ox.graph_from_place(place, network_type='walk')

The overall structure of the matrix is designed to calculate similarity between users based on their origin and destination locations using the Maximum Inner Product Search (MIPS) method.

To build this matrix, I first identify the graph's nodes and assume that each node has two distinct roles: one as an origin and another as a destination. Therefore, for a graph with *n* nodes, the final matrix will have *2n* columns; half of the columns are dedicated to origin features, and the other half to destination features.

To populate the matrix, each row corresponds to a user. First, I take the user's origin location and find the 10 closest nodes to it based on walking distance. These distances are then normalized and placed in the columns corresponding to the "origin role" of those nodes in the user's row. The same process is repeated for the destination location: the 10 closest nodes to the destination are selected, their distances are normalized, and they are entered into the columns related to the "destination role" of those nodes.

This bipartite matrix structure (separating origin and destination) offers several key advantages. First, it ensures that only similarities of the type "same origin" or "same destination" are calculated. In contrast, if a user's origin is close to another user's destination, these features are placed in separate columns, so their inner product is not affected. This prevents false similarities and ensures that only valid spatial proximity between users is considered as true similarity.

Finally, after constructing this sparse matrix, I use the Maximum Inner Product Search algorithm to find users with more similar origins and destinations for each user.

please write the functions (or class) that gets the input as a list of UserLocation like:
UserLocation(user_id=1, origin_lat=35.9725713, origin_lng=50.7328994, destination_lat=35.9591762, destination_lng=50.6883034, stored_at=datetime.datetime(2025, 8, 1, 22, 6, 31, 467604))
which UserLocation is:
@dataclass
class UserLocation:
    user_id: int
    origin_lat: float
    origin_lng: float
    destination_lat: float
    destination_lng: float
    stored_at: datetime

    @property
    def origin_coords(self) -> Tuple[float, float]:
        return (self.origin_lat, self.origin_lng)

    @property
    def destination_coords(self) -> Tuple[float, float]:
        return (self.destination_lat, self.destination_lng)

    def to_dict(self) -> Dict:
        return {
            'user_id': self.user_id,
            'origin_lat': self.origin_lat,
            'origin_lng': self.origin_lng,
            'destination_lat': self.destination_lat,
            'destination_lng': self.destination_lng,
            'stored_at': self.stored_at.isoformat()
        }
        
        
and return the ouput (list of group) like:
groups = []
@dataclass
class ClusterGroup:
    group_id: str
    users: List[UserLocation]
    created_at: datetime
    meeting_point_origin: Optional[Tuple[float, float]] = None
    meeting_point_destination: Optional[Tuple[float, float]] = None
    status: str = "forming"  # forming, complete, expired
    def is_complete(self) -> bool:
        return len(self.users) == 3
    def has_user(self, user_id: int) -> bool:
        return any(u.user_id == user_id for u in self.users)
    def get_user_ids(self) -> List[int]:
        return [u.user_id for u in self.users]
    def to_dict(self) -> Dict:
        return {
            'group_id': self.group_id,
            'users': [user.to_dict() for user in self.users],
            'created_at': self.created_at.isoformat(),
            'meeting_point_origin': self.meeting_point_origin,
            'meeting_point_destination': self.meeting_point_destination,
            'status': self.status,
            'user_count': len(self.users)
        }
group = ClusterGroup(
group_id=f"group_{user1.user_id}_{best_pair.user_id}_{third_user.user_id}_{int(time.time())}",
users=group_users,
created_at=datetime.now(timezone.utc),
meeting_point_origin=origin_meeting,
meeting_point_destination=dest_meeting,
status="complete"
)
groups.append(group)

The output groups are limited to a maximum of 3 people but with the threshold similarity (if pass the threshold for the similarity).
Some notes:
To optimize and speed up the process, use precomputation where possible.
For example, if you need the walking distance between nodes, precompute the distances between 200 nearest nodes of each node and use those values at runtime.
Similarly, if you need to find the 10 nearest nodes based on walking distance, compute and store that information in advance.
Apply this approach to any other tasks that can be precomputed.

please write the python code.





how can i speed up this process:
self.G = ox.graph_from_place(self.place, network_type='walk')
nearest_node = ox.distance.nearest_nodes(self.G, lng, lat)

i don't want to harm my precesion considerebly.








